# F319 Crawler - Hybrid Selenium + Requests

Tool crawl dá»¯ liá»‡u má»›i nháº¥t tá»« diá»…n Ä‘Ã n F319.com vá»›i hai cháº¿ Ä‘á»™: **Hybrid** (nhanh) vÃ  **Full** (Ä‘áº§y Ä‘á»§).

## TÃ­nh nÄƒng ná»•i báº­t âš¡

- âœ… **Incremental Crawling**: Láº§n 2+ chá»‰ crawl posts má»›i â†’ Nhanh hÆ¡n 10-50 láº§n
- âœ… **Reverse Crawling**: Crawl ngÆ°á»£c tá»« trang cuá»‘i (posts má»›i nháº¥t)
- âœ… **Early Stop**: Dá»«ng ngay khi gáº·p posts cÅ© â†’ Tiáº¿t kiá»‡m thá»i gian
- âœ… **Batch Insert**: Insert 100 posts/láº§n thay vÃ¬ tá»«ng post â†’ Nhanh gáº¥p 5-10 láº§n
- âœ… **Parallel Threads**: Crawl 2-3 threads cÃ¹ng lÃºc â†’ TÄƒng tá»‘c 2x
- âœ… **Hybrid Mode**: Selenium (navigation) + Requests (content) â†’ Tá»‘c Ä‘á»™ tá»‘i Æ°u
- âœ… **Resume Support**: Dá»«ng/cháº¡y láº¡i báº¥t cá»© lÃºc nÃ o

## Cáº¥u trÃºc thÆ° má»¥c

```
Crawl/
â”œâ”€â”€ config.py                # Cáº¥u hÃ¬nh crawler, database, selectors
â”œâ”€â”€ database.py              # PostgreSQL operations vá»›i batch insert
â”œâ”€â”€ f319_hybrid_crawler.py   # Hybrid: Selenium + Requests (NHANH)
â”œâ”€â”€ f319_full_crawler.py     # Full: Crawl toÃ n bá»™ tá»« homepage
â”œâ”€â”€ main.py                  # CLI entry point
â”œâ”€â”€ requirements.txt         # Dependencies
â”œâ”€â”€ .env.example             # Template biáº¿n mÃ´i trÆ°á»ng
â””â”€â”€ README.md                # Documentation
```

## CÃ i Ä‘áº·t

### 1. Táº¡o virtual environment

```bash
cd Crawl
python -m venv venv
venv\Scripts\activate  # Windows
# hoáº·c
source venv/bin/activate  # Linux/Mac
```

### 2. CÃ i Ä‘áº·t dependencies

```bash
pip install -r requirements.txt
```

### 3. Cáº¥u hÃ¬nh database

Copy `.env.example` thÃ nh `.env`:

```bash
copy .env.example .env  # Windows
# hoáº·c
cp .env.example .env    # Linux/Mac
```

Chá»‰nh sá»­a `.env`:
```env
DB_HOST=localhost
DB_PORT=5432
DB_NAME=f319_data
DB_USER=postgres
DB_PASSWORD=your_password
```

**LÆ°u Ã½:** Náº¿u gáº·p lá»—i káº¿t ná»‘i, thá»­ `DB_HOST=127.0.0.1`

### 4. Táº¡o database PostgreSQL

```sql
CREATE DATABASE f319_data;
```

CÃ¡c báº£ng sáº½ tá»± Ä‘á»™ng táº¡o khi cháº¡y crawler.

## Sá»­ dá»¥ng

### ğŸš€ Hybrid Mode (Khuyáº¿n nghá»‹)

Crawl nhanh vá»›i Selenium (navigation) + Requests (content):

```bash
# Crawl 5 pages (máº·c Ä‘á»‹nh)
python main.py hybrid

# Crawl sá»‘ trang tÃ¹y chá»‰nh
python main.py hybrid --pages 10

# Cháº¡y headless (khÃ´ng hiá»ƒn thá»‹ browser)
python main.py hybrid --headless

# Káº¿t há»£p options
python main.py hybrid --pages 3 --headless
```

**Tá»‘c Ä‘á»™:**
- Láº§n 1: Thread 1000 pages â†’ ~17 phÃºt
- Láº§n 2+: Chá»‰ ~30 giÃ¢y (nhá» incremental crawl)

### ğŸ”¥ Full Mode

Crawl toÃ n bá»™ posts tá»« homepage "HÃ´m nay cÃ³ gÃ¬?":

```bash
# Crawl táº¥t cáº£ pages vÃ  posts
python main.py full

# Headless mode
python main.py full --headless
```

## CÃ¡ch hoáº¡t Ä‘á»™ng

### Hybrid Mode Architecture

```
1. Selenium láº¥y danh sÃ¡ch threads tá»« "Find New Posts"
         â†“
2. Vá»›i má»—i thread:
   - Láº¥y last_post_id Ä‘Ã£ crawl (náº¿u cÃ³)
   - Requests fetch page cuá»‘i â†’ Ä‘áº§u (REVERSE)
   - Check post_exists() â†’ Skip posts cÅ©
   - Gáº·p 20 posts cÅ© liÃªn tiáº¿p â†’ Dá»ªNG (early stop)
   - Buffer 100 posts â†’ Batch insert
         â†“
3. Update last_post_id â†’ Láº§n sau chá»‰ crawl incremental
```

### Luá»“ng chi tiáº¿t

```
python main.py hybrid --pages 5
    â”‚
    â”œâ”€â†’ Káº¿t ná»‘i PostgreSQL
    â”‚   â”œâ”€â†’ Táº¡o báº£ng f319_list, f319_post
    â”‚   â””â”€â†’ ThÃªm column last_post_id (náº¿u chÆ°a cÃ³)
    â”‚
    â”œâ”€â†’ Khá»Ÿi Ä‘á»™ng Chrome WebDriver
    â”‚
    â”œâ”€â†’ Láº·p qua 5 trang new posts (Selenium):
    â”‚   â”œâ”€â†’ Load https://f319.com/find-new/posts?page=X
    â”‚   â”œâ”€â†’ Láº¥y danh sÃ¡ch 20 threads
    â”‚   â””â”€â†’ LÆ°u thread info â†’ f319_list
    â”‚
    â”œâ”€â†’ Crawl 2 threads song song (ThreadPoolExecutor):
    â”‚   â”‚
    â”‚   â””â”€â†’ Vá»›i má»—i thread (Requests):
    â”‚       â”œâ”€â†’ Láº¥y last_post_id tá»« DB
    â”‚       â”œâ”€â†’ Fetch page cuá»‘i â†’ page Ä‘áº§u (REVERSE)
    â”‚       â”‚   â”‚
    â”‚       â”‚   â”œâ”€â†’ Check post_exists(post_id)
    â”‚       â”‚   â”œâ”€â†’ Gáº·p last_post_id â†’ Dá»ªNG
    â”‚       â”‚   â”œâ”€â†’ Gáº·p 20 posts cÅ© liÃªn tiáº¿p â†’ Dá»ªNG
    â”‚       â”‚   â””â”€â†’ Buffer posts â†’ Batch insert 100 posts/láº§n
    â”‚       â”‚
    â”‚       â””â”€â†’ Update last_post_id â†’ DB
    â”‚
    â”œâ”€â†’ ÄÃ³ng Chrome
    â”œâ”€â†’ Hiá»ƒn thá»‹ stats
    â””â”€â†’ ÄÃ³ng DB connection
```

## Database Schema

### Báº£ng f319_list

| Column         | Type         | Description              |
|----------------|--------------|--------------------------|
| id             | VARCHAR(255) | Primary key              |
| title          | TEXT         | TiÃªu Ä‘á» thread           |
| author         | VARCHAR(255) | TÃ¡c giáº£                  |
| start_date     | VARCHAR(100) | NgÃ y táº¡o                 |
| last_post_date | VARCHAR(100) | NgÃ y post cuá»‘i           |
| link           | TEXT         | URL thread               |
| views          | VARCHAR(50)  | Sá»‘ lÆ°á»£t xem              |
| replies        | VARCHAR(50)  | Sá»‘ replies               |
| **last_post_id** | **VARCHAR(255)** | **ID post cuá»‘i Ä‘Ã£ crawl** |
| created_at     | TIMESTAMP    | Thá»i gian crawl          |

### Báº£ng f319_post

| Column      | Type         | Description              |
|-------------|--------------|--------------------------|
| id          | VARCHAR(255) | Primary key              |
| thread_id   | VARCHAR(255) | ID cá»§a thread            |
| author      | VARCHAR(255) | TÃ¡c giáº£                  |
| author_link | TEXT         | Link profile tÃ¡c giáº£     |
| post_date   | BIGINT       | Unix timestamp           |
| content     | TEXT         | Ná»™i dung post            |
| created_at  | TIMESTAMP    | Thá»i gian crawl          |

## TÃ­nh nÄƒng

### âš¡ Performance Optimizations

1. **Incremental Crawling**
   - LÆ°u `last_post_id` sau má»—i láº§n crawl
   - Láº§n sau gáº·p `last_post_id` â†’ dá»«ng ngay
   - **Káº¿t quáº£**: Thread 1000 pages chá»‰ máº¥t ~30s thay vÃ¬ 17 phÃºt

2. **Reverse Crawling**
   - Crawl tá»« page cuá»‘i â†’ page Ä‘áº§u (posts má»›i á»Ÿ cuá»‘i)
   - Gáº·p posts cÅ© sá»›m hÆ¡n â†’ dá»«ng nhanh hÆ¡n

3. **Early Stop**
   - Gáº·p 20 posts cÅ© liÃªn tiáº¿p â†’ dá»«ng crawl
   - Config: `early_stop_threshold: int = 20`

4. **Batch Insert**
   - Insert 100 posts/láº§n thay vÃ¬ tá»«ng post
   - **Nhanh gáº¥p 5-10 láº§n** khi insert nhiá»u posts
   - Config: `batch_size: int = 100`

5. **Parallel Thread Crawling**
   - Crawl 2 threads khÃ¡c nhau cÃ¹ng lÃºc
   - **Nhanh gáº¥p 2 láº§n** so vá»›i tuáº§n tá»±
   - Config: `max_thread_workers: int = 2`

6. **Hybrid Architecture**
   - Selenium: Navigation + extract thread list
   - Requests: Fetch thread content (nhanh hÆ¡n 10x)

### âœ… Stability Features

- âœ… **Resume crawling**: Dá»«ng/cháº¡y láº¡i báº¥t cá»© lÃºc nÃ o
- âœ… **Auto-retry**: Retry 3 láº§n khi fetch page tháº¥t báº¡i
- âœ… **Smart delay**: Random delay 3-15s giá»¯a threads
- âœ… **Skip list**: Bá» qua threads khÃ´ng mong muá»‘n (config trong `config.py`)
- âœ… **Clean content**: Loáº¡i bá» quote vÃ  attribution
- âœ… **Headless mode**: Cháº¡y áº©n browser
- âœ… **Duplicate prevention**: `ON CONFLICT DO NOTHING`
- âœ… **Auto schema**: Tá»± Ä‘á»™ng táº¡o báº£ng vÃ  index

## Cáº¥u hÃ¬nh

File [config.py](config.py):

```python
# Timeouts
page_load_timeout: int = 60      # Timeout load page (giÃ¢y)
implicit_wait: int = 10          # Wait element xuáº¥t hiá»‡n
delay_between_requests: int = 2  # Delay giá»¯a requests

# Retry
max_retries: int = 3             # Sá»‘ láº§n retry khi lá»—i
retry_delay: int = 3             # Delay giá»¯a retry

# Performance
max_thread_workers: int = 2      # Sá»‘ threads crawl song song
early_stop_threshold: int = 20   # Sá»‘ posts cÅ© Ä‘á»ƒ dá»«ng crawl
batch_size: int = 100            # Sá»‘ posts insert cÃ¹ng lÃºc

# Delays
min_random_delay: int = 3        # Random delay min
max_random_delay: int = 15       # Random delay max
```

## So sÃ¡nh Hybrid vs Full

| TÃ­nh nÄƒng | Hybrid | Full |
|-----------|--------|------|
| Navigation | Selenium | Selenium |
| Content Fetch | **Requests** âš¡ | Selenium |
| Tá»‘c Ä‘á»™ | **Nhanh** (10x) | Cháº­m |
| Incremental | âœ… | âœ… |
| Parallel Threads | âœ… (2 threads) | âŒ |
| Batch Insert | âœ… (100/láº§n) | âŒ (tá»«ng post) |
| Use case | **Crawl thÆ°á»ng xuyÃªn** | Láº§n Ä‘áº§u/full sync |

## LÆ°u Ã½ quan trá»ng

### 1. Incremental Crawling

**Láº§n crawl Ä‘áº§u:**
```
Thread 246 pages â†’ Crawl háº¿t 246 pages â†’ LÆ°u last_post_id
Thá»i gian: ~17 phÃºt
```

**Láº§n crawl thá»© 2+ (cÃ³ posts má»›i):**
```
Thread 248 pages â†’ Crawl page 248, 247 â†’ Gáº·p 20 posts cÅ© â†’ Dá»ªNG
Thá»i gian: ~30 giÃ¢y (nhanh hÆ¡n 34x!)
```

**Láº§n crawl thá»© 2+ (khÃ´ng cÃ³ posts má»›i):**
```
Thread 246 pages â†’ Crawl page 246 â†’ Gáº·p 20 posts cÅ© â†’ Dá»ªNG ngay
Thá»i gian: ~10 giÃ¢y
```

### 2. Parallel Threads

- Crawl **2 threads khÃ¡c nhau** cÃ¹ng lÃºc (khÃ´ng pháº£i 2 pages cá»§a 1 thread)
- F319.com cÃ³ anti-bot â†’ crawl nhiá»u pages cá»§a 1 thread cÃ¹ng lÃºc bá»‹ block
- CÃ³ thá»ƒ tÄƒng `max_thread_workers: 3` nhÆ°ng rá»§i ro rate limit

### 3. ChromeDriver

Tool dÃ¹ng `webdriver-manager` tá»± Ä‘á»™ng download ChromeDriver. Náº¿u lá»—i:
```env
CHROMEDRIVER_PATH=D:\path\to\chromedriver.exe
```

### 4. Duplicate Handling

Code dÃ¹ng `ON CONFLICT DO NOTHING`:
- Data cÅ© **KHÃ”NG** bá»‹ update khi crawl láº¡i
- Muá»‘n sá»­a data lá»—i â†’ xÃ³a database vÃ  crawl láº¡i

## Troubleshooting

### âŒ Lá»—i: `password authentication failed`

**Giáº£i phÃ¡p:**
1. Kiá»ƒm tra file `.env` Ä‘Ã£ tá»“n táº¡i
2. Thá»­ `DB_HOST=127.0.0.1` thay vÃ¬ `localhost`
3. Verify password PostgreSQL

### âŒ Lá»—i ChromeDriver

**Giáº£i phÃ¡p:**
- Cáº­p nháº­t Chrome lÃªn version má»›i nháº¥t
- XÃ³a cache: `%USERPROFILE%\.wdm\` (Windows) hoáº·c `~/.wdm/` (Linux/Mac)
- Set manual path trong `.env`

### âŒ Timeout khi load page

**Giáº£i phÃ¡p:**
- TÄƒng `page_load_timeout: 90` trong [config.py](config.py#L28)
- Kiá»ƒm tra internet
- Cháº¡y khÃ´ng headless Ä‘á»ƒ debug

### âŒ Crawl cháº­m dÃ¹ Ä‘Ã£ optimize

**NguyÃªn nhÃ¢n:** Láº§n crawl Ä‘áº§u tiÃªn luÃ´n cháº­m (pháº£i crawl háº¿t)

**Giáº£i phÃ¡p:**
- Cháº¡y láº§n 2+ sáº½ nhanh hÆ¡n nhiá»u (incremental)
- Giáº£m `delay_between_requests: 1` (rá»§i ro: rate limit)
- TÄƒng `max_thread_workers: 3` (rá»§i ro: bá»‹ block)

### âš ï¸ Rate Limiting / QUOTA_EXCEEDED

**NguyÃªn nhÃ¢n:** F319.com phÃ¡t hiá»‡n crawl quÃ¡ nhanh

**Giáº£i phÃ¡p:**
- Giáº£m `max_thread_workers: 1`
- TÄƒng `delay_between_requests: 3`
- Cháº¡y vÃ o giá» Ã­t ngÆ°á»i dÃ¹ng (Ä‘Ãªm khuya)

## Performance Metrics

### Thread 1000 pages

| Láº§n crawl | PhÆ°Æ¡ng phÃ¡p | Thá»i gian |
|-----------|-------------|-----------|
| Láº§n 1 | Hybrid (tuáº§n tá»±, insert tá»«ng post) | ~34 phÃºt |
| Láº§n 1 | Hybrid (parallel threads + batch insert) | **~17 phÃºt** |
| Láº§n 2+ | Hybrid (incremental, khÃ´ng posts má»›i) | **~30 giÃ¢y** |
| Láº§n 2+ | Hybrid (incremental, 50 posts má»›i) | **~2 phÃºt** |

### Optimization Breakdown

| Tá»‘i Æ°u | TÄƒng tá»‘c |
|--------|----------|
| Batch insert (100 posts/láº§n) | **5-10x** |
| Parallel threads (2 cÃ¹ng lÃºc) | **2x** |
| Incremental crawl + early stop | **10-50x** |
| **Tá»•ng cá»™ng (láº§n 2+)** | **~100x** |

## License

MIT License - Free to use and modify.

## Contributing

Pull requests welcome! Äáº·c biá»‡t:
- Tá»‘i Æ°u performance hÆ¡n ná»¯a
- Support rotating proxies
- Async/asyncio cho requests
- Export to CSV/JSON
